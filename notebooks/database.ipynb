{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc7c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995b342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações de conexão com o PostgreSQL\n",
    "DB_HOST = \"airflow-postgres\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_USER = os.getenv('POSTGRES_USER')\n",
    "DB_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "DB_NAME = \"azurecost\"\n",
    "\n",
    "conn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "642bc180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banco de dados 'azurecost' já existe.\n",
      "Tabela 'azure_cost_data' criada com sucesso no banco de dados 'azurecost'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Conecta-se ao banco de dados 'postgres' para criar o banco 'azurecost'\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=\"postgres\",\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Verifica e cria o banco de dados 'azurecost' se não existir\n",
    "    cur.execute(f\"SELECT 1 FROM pg_database WHERE datname='{DB_NAME}'\")\n",
    "    exists = cur.fetchone()\n",
    "    if not exists:\n",
    "        cur.execute(f\"CREATE DATABASE {DB_NAME}\")\n",
    "        print(f\"Banco de dados '{DB_NAME}' criado com sucesso.\")\n",
    "    else:\n",
    "        print(f\"Banco de dados '{DB_NAME}' já existe.\")\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()  # Fecha a conexão com 'postgres'\n",
    "\n",
    "    # Conecta-se ao banco de dados 'azurecost' para criar a tabela\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Comando SQL para criar a tabela 'azure_cost_data'\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS azure_cost_data (\n",
    "        ResourceName VARCHAR,\n",
    "        SubscriptionId VARCHAR,\n",
    "        ResourceGroup VARCHAR,\n",
    "        Provider VARCHAR,\n",
    "        StatusRecourse VARCHAR,\n",
    "        PreTaxCost DOUBLE PRECISION,\n",
    "        Pct_Change DOUBLE PRECISION,\n",
    "        Currency VARCHAR,\n",
    "        UsageDate DATE,\n",
    "        TendenciaCusto VARCHAR,\n",
    "        PrevisaoProxima DOUBLE PRECISION\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    cur.execute(create_table_query)\n",
    "    conn.commit()\n",
    "    print(f\"Tabela 'azure_cost_data' criada com sucesso no banco de dados '{DB_NAME}'.\")\n",
    "\n",
    "    cur.close()\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Erro ao conectar ou criar o banco de dados/tabela: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f147388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Última partição disponível: 2025-07-28\n",
      "+------------+------------------------------------+---------------+-------------+--------------+----------+----------+--------+-------------------+--------------+---------------+\n",
      "|ResourceName|SubscriptionId                      |ResourceGroup  |Provider     |StatusRecourse|PreTaxCost|Pct_Change|Currency|UsageDate          |TendenciaCusto|PrevisaoProxima|\n",
      "+------------+------------------------------------+---------------+-------------+--------------+----------+----------+--------+-------------------+--------------+---------------+\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 19:15:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 19:10:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 19:05:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 19:00:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 18:55:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 18:50:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 18:45:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 18:40:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 18:35:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 18:30:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 18:25:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 18:20:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 18:15:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 18:10:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 18:05:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 18:00:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 17:55:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 17:50:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 17:45:00|Estável       |0.0            |\n",
      "|appfunckabum|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject|microsoft.web|Ativo         |0.0       |0.0       |BRL     |2025-07-28 17:40:00|Estável       |0.0            |\n",
      "+------------+------------------------------------+---------------+-------------+--------------+----------+----------+--------+-------------------+--------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import DeltaTable\n",
    "import os\n",
    "\n",
    "DELTA_LAKE_PACKAGE = \"io.delta:delta-core_2.12:3.3.2\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark Delta Lake MinIO Save\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", os.getenv(\"KEY_ACCESS\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", os.getenv(\"KEY_SECRETS\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Caminho para a tabela Delta (no seu MinIO)\n",
    "gold_path = \"s3a://azurecost/gold\"\n",
    "\n",
    "# Inicializa objeto DeltaTable\n",
    "delta_table = DeltaTable.forPath(spark, gold_path)\n",
    "\n",
    "# Obtém todos os valores únicos da partição\n",
    "partitions_df = delta_table.toDF().select(\"data_ref\").distinct()\n",
    "\n",
    "# Obtém o valor mais recente da partição\n",
    "max_partition = partitions_df.agg({\"data_ref\": \"max\"}).collect()[0][0]\n",
    "print(f\"Última partição disponível: {max_partition}\")\n",
    "\n",
    "# Lê os dados somente da última partição\n",
    "df = spark.read.format(\"delta\").load(gold_path).filter(f\"data_ref = '{max_partition}'\")\n",
    "\n",
    "df = df.select(\n",
    "    \"ResourceName\",\n",
    "    \"SubscriptionId\",\n",
    "    \"ResourceGroup\",\n",
    "    \"Provider\",\n",
    "    \"StatusRecourse\",\n",
    "    \"PreTaxCost\",\n",
    "    \"Pct_Change\",\n",
    "    \"Currency\",\n",
    "    \"UsageDate\",\n",
    "    \"TendenciaCusto\",\n",
    "    \"PrevisaoProxima\"\n",
    ")\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "262ac6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados inseridos com sucesso na tabela 'azure_cost_data'.\n"
     ]
    }
   ],
   "source": [
    "jdbc_url = f\"jdbc:postgresql://{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "properties = {\n",
    "    \"user\": DB_USER,\n",
    "    \"password\": DB_PASSWORD,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "df.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"url\", jdbc_url) \\\n",
    "  .option(\"dbtable\", \"azure_cost_data\") \\\n",
    "  .option(\"user\", DB_USER) \\\n",
    "  .option(\"password\", DB_PASSWORD) \\\n",
    "  .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .save()\n",
    "\n",
    "print(\"Dados inseridos com sucesso na tabela 'azure_cost_data'.\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79091017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bancos de dados disponíveis:\n",
      "postgres\n",
      "airflow\n",
      "template1\n",
      "template0\n",
      "azurecost\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "\n",
    "DB_HOST = \"airflow-postgres\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_USER = os.getenv('POSTGRES_USER')\n",
    "DB_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "\n",
    "# Abre conexão com o banco padrão\n",
    "conn = psycopg2.connect(\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=\"postgres\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Executa a consulta para listar os bancos de dados\n",
    "cur.execute(\"SELECT datname FROM pg_database;\")\n",
    "databases = cur.fetchall()\n",
    "\n",
    "print(\"Bancos de dados disponíveis:\")\n",
    "for db in databases:\n",
    "    print(db[0])\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25211f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelas no banco 'airflow':\n",
      "log\n",
      "dag_priority_parsing_request\n",
      "job\n",
      "slot_pool\n",
      "callback_request\n",
      "dag_code\n",
      "dag_pickle\n",
      "ab_user\n",
      "ab_register_user\n",
      "connection\n",
      "sla_miss\n",
      "variable\n",
      "import_error\n",
      "serialized_dag\n",
      "dataset_alias\n",
      "dataset_alias_dataset\n",
      "dataset\n",
      "dataset_alias_dataset_event\n",
      "dataset_event\n",
      "dag_schedule_dataset_alias_reference\n",
      "dag\n",
      "dag_schedule_dataset_reference\n",
      "task_outlet_dataset_reference\n",
      "dataset_dag_run_queue\n",
      "log_template\n",
      "dag_run\n",
      "dag_tag\n",
      "dag_owner_attributes\n",
      "ab_permission\n",
      "ab_permission_view\n",
      "ab_view_menu\n",
      "ab_user_role\n",
      "ab_role\n",
      "dag_warning\n",
      "dagrun_dataset_event\n",
      "trigger\n",
      "task_instance\n",
      "dag_run_note\n",
      "ab_permission_view_role\n",
      "rendered_task_instance_fields\n",
      "task_fail\n",
      "task_map\n",
      "task_reschedule\n",
      "xcom\n",
      "task_instance_note\n",
      "task_instance_history\n",
      "session\n",
      "alembic_version\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "\n",
    "DB_HOST = \"airflow-postgres\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_USER = os.getenv('POSTGRES_USER')\n",
    "DB_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "DB_NAME = \"airflow\"\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=DB_NAME\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Query para listar tabelas do schema 'public'\n",
    "cur.execute(\"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'public'\n",
    "    AND table_type = 'BASE TABLE';\n",
    "\"\"\")\n",
    "\n",
    "tables = cur.fetchall()\n",
    "\n",
    "print(f\"Tabelas no banco '{DB_NAME}':\")\n",
    "for table in tables:\n",
    "    print(table[0])\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb2c33f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas da tabela 'dag':\n",
      "Nome: dag_id, Tipo: character varying, Pode ser NULL: NO, Default: None\n",
      "Nome: root_dag_id, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: is_paused, Tipo: boolean, Pode ser NULL: YES, Default: None\n",
      "Nome: is_subdag, Tipo: boolean, Pode ser NULL: YES, Default: None\n",
      "Nome: is_active, Tipo: boolean, Pode ser NULL: YES, Default: None\n",
      "Nome: last_parsed_time, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n",
      "Nome: last_pickled, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n",
      "Nome: last_expired, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n",
      "Nome: scheduler_lock, Tipo: boolean, Pode ser NULL: YES, Default: None\n",
      "Nome: pickle_id, Tipo: integer, Pode ser NULL: YES, Default: None\n",
      "Nome: fileloc, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: processor_subdir, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: owners, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: dag_display_name, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: description, Tipo: text, Pode ser NULL: YES, Default: None\n",
      "Nome: default_view, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: schedule_interval, Tipo: text, Pode ser NULL: YES, Default: None\n",
      "Nome: timetable_description, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: dataset_expression, Tipo: json, Pode ser NULL: YES, Default: None\n",
      "Nome: max_active_tasks, Tipo: integer, Pode ser NULL: NO, Default: None\n",
      "Nome: max_active_runs, Tipo: integer, Pode ser NULL: YES, Default: None\n",
      "Nome: max_consecutive_failed_dag_runs, Tipo: integer, Pode ser NULL: NO, Default: None\n",
      "Nome: has_task_concurrency_limits, Tipo: boolean, Pode ser NULL: NO, Default: None\n",
      "Nome: has_import_errors, Tipo: boolean, Pode ser NULL: YES, Default: false\n",
      "Nome: next_dagrun, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n",
      "Nome: next_dagrun_data_interval_start, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n",
      "Nome: next_dagrun_data_interval_end, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n",
      "Nome: next_dagrun_create_after, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "\n",
    "DB_HOST = \"airflow-postgres\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_USER = os.getenv('POSTGRES_USER')\n",
    "DB_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "DB_NAME = \"airflow\" \n",
    "\n",
    "table_name = 'dag'\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=DB_NAME\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT column_name, data_type, is_nullable, column_default\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = 'public'\n",
    "    AND table_name = %s\n",
    "    ORDER BY ordinal_position;\n",
    "\"\"\", (table_name,))\n",
    "\n",
    "columns = cur.fetchall()\n",
    "\n",
    "print(f\"Colunas da tabela '{table_name}':\")\n",
    "for col in columns:\n",
    "    print(f\"Nome: {col[0]}, Tipo: {col[1]}, Pode ser NULL: {col[2]}, Default: {col[3]}\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6bab6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela 'azure_cost_data' excluída com sucesso.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    drop_table_query = \"DROP TABLE IF EXISTS azure_cost_data;\"\n",
    "    cur.execute(drop_table_query)\n",
    "    print(f\"Tabela 'azure_cost_data' excluída com sucesso.\")\n",
    "\n",
    "    cur.close()\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Erro ao excluir a tabela: {e}\")\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec007fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banco de dados 'azurecost' excluído com sucesso.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=\"postgres\",  # banco diferente do que será dropado\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Fecha conexões ativas no banco azurecost\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT pg_terminate_backend(pid) \n",
    "        FROM pg_stat_activity \n",
    "        WHERE datname = %s;\n",
    "    \"\"\", (DB_NAME,))\n",
    "\n",
    "    # Exclui o banco azurecost\n",
    "    cur.execute(f\"DROP DATABASE IF EXISTS {DB_NAME};\")\n",
    "    print(f\"Banco de dados '{DB_NAME}' excluído com sucesso.\")\n",
    "\n",
    "    cur.close()\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Erro ao excluir o banco de dados: {e}\")\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
