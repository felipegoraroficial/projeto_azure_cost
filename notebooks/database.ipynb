{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc7c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995b342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações de conexão com o PostgreSQL\n",
    "DB_HOST = \"airflow-postgres\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_USER = os.getenv('POSTGRES_USER')\n",
    "DB_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "DB_NAME = \"azurecost\"\n",
    "\n",
    "conn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00457933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banco de dados 'azurecost' criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Conecta-se ao banco de dados 'postgres' para criar o banco 'azurecost'\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=\"postgres\",\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Verifica e cria o banco de dados 'azurecost' se não existir\n",
    "    cur.execute(f\"SELECT 1 FROM pg_database WHERE datname='{DB_NAME}'\")\n",
    "    exists = cur.fetchone()\n",
    "    if not exists:\n",
    "        cur.execute(f\"CREATE DATABASE {DB_NAME}\")\n",
    "        print(f\"Banco de dados '{DB_NAME}' criado com sucesso.\")\n",
    "    else:\n",
    "        print(f\"Banco de dados '{DB_NAME}' já existe.\")\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Erro ao conectar ou criar o banco de dados: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "642bc180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela 'resources' criada com sucesso no banco de dados 'azurecost'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    # Conecta-se ao banco de dados 'azurecost' para criar a tabela\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Comando SQL para criar a tabela 'resources'\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS resources (\n",
    "        Id SERIAL PRIMARY KEY,\n",
    "        ResourceName VARCHAR,\n",
    "        SubscriptionId VARCHAR,\n",
    "        ResourceGroup VARCHAR,\n",
    "        Provider VARCHAR,\n",
    "        StatusRecourse VARCHAR,\n",
    "        Currency VARCHAR,\n",
    "        TendenciaCusto VARCHAR\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    cur.execute(create_table_query)\n",
    "    conn.commit()\n",
    "    print(f\"Tabela 'resources' criada com sucesso no banco de dados '{DB_NAME}'.\")\n",
    "\n",
    "    cur.close()\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Erro ao criar tabela: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f712376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela 'costresources' criada com sucesso no banco de dados 'azurecost'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    # Conecta-se ao banco de dados 'azurecost' para criar a tabela\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Comando SQL para criar a tabela 'costresources'\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS costresources (\n",
    "        Id SERIAL,\n",
    "        PreTaxCost DOUBLE PRECISION,\n",
    "        Pct_Change DOUBLE PRECISION,\n",
    "        PrevisaoProxima DOUBLE PRECISION,\n",
    "        UsageDate TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    cur.execute(create_table_query)\n",
    "    conn.commit()\n",
    "    print(f\"Tabela 'costresources' criada com sucesso no banco de dados '{DB_NAME}'.\")\n",
    "\n",
    "    cur.close()\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Erro ao criar tabela: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae307b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|              concat| Id|\n",
      "+--------------------+---+\n",
      "|appfunckabum_da48...|  1|\n",
      "|appfuncmagalu_da4...|  2|\n",
      "|dbstorage7ifgyhji...|  3|\n",
      "|nintendoservplan_...|  4|\n",
      "|nintendostorageac...|  5|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import max, col,row_number, concat_ws\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "\n",
    "DELTA_LAKE_PACKAGE = \"io.delta:delta-core_2.12:3.3.2\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark Delta Lake MinIO Save\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", os.getenv(\"KEY_ACCESS\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", os.getenv(\"KEY_SECRETS\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Caminho para a tabela Delta (no seu MinIO)\n",
    "gold_path = \"s3a://azurecost/gold\"\n",
    "\n",
    "# Lê os dados somente da última partição\n",
    "df = spark.read.format(\"delta\").load(gold_path)\n",
    "\n",
    "df_id = df.withColumn('concat', concat_ws(\"_\", col(\"ResourceName\"), col(\"SubscriptionId\"), col(\"ResourceGroup\")))\n",
    "\n",
    "df_id = df_id.select(\n",
    "    \"concat\",\n",
    "    \"ResourceName\",\n",
    "    \"SubscriptionId\",\n",
    "    \"ResourceGroup\"\n",
    ").distinct()\n",
    "\n",
    "window_spec = Window.orderBy(\"concat\")\n",
    "\n",
    "df_id = df_id.withColumn(\"Id\", row_number().over(window_spec))\n",
    "\n",
    "df_id = df_id.select(\n",
    "    \"concat\",\n",
    "    \"Id\"\n",
    ").distinct()\n",
    "\n",
    "df_id.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f147388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------+------------------------------------+-------------------------------------+-----------------+--------------+--------+--------------+\n",
      "|Id |ResourceName          |SubscriptionId                      |ResourceGroup                        |Provider         |StatusRecourse|Currency|TendenciaCusto|\n",
      "+---+----------------------+------------------------------------+-------------------------------------+-----------------+--------------+--------+--------------+\n",
      "|1  |appfunckabum          |da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject                      |microsoft.web    |Ativo         |BRL     |Estável       |\n",
      "|2  |appfuncmagalu         |da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject                      |microsoft.web    |Ativo         |BRL     |Estável       |\n",
      "|3  |dbstorage7ifgyhjijpdgi|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendodatabrickswi86no-workspace-rg|microsoft.storage|Ativo         |BRL     |Estável       |\n",
      "|4  |nintendoservplan      |da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject                      |microsoft.web    |Ativo         |BRL     |Estável       |\n",
      "|5  |nintendostorageaccount|da483b95-1caf-404c-bfe4-36abef87f6e6|nintendoproject                      |microsoft.storage|Ativo         |BRL     |Estável       |\n",
      "+---+----------------------+------------------------------------+-------------------------------------+-----------------+--------------+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(\n",
    "    \"ResourceName\",\n",
    "    \"SubscriptionId\",\n",
    "    \"ResourceGroup\",\n",
    "    \"Provider\",\n",
    "    \"StatusRecourse\",\n",
    "    \"PreTaxCost\",\n",
    "    \"Pct_Change\",\n",
    "    \"Currency\",\n",
    "    \"UsageDate\",\n",
    "    \"TendenciaCusto\",\n",
    "    \"PrevisaoProxima\"\n",
    ")\n",
    "\n",
    "latest_dates_df = df.groupBy(\"ResourceName\").agg(max(\"UsageDate\").alias(\"MaxUsageDate\"))\n",
    "\n",
    "window_spec = Window.partitionBy(\"ResourceName\").orderBy(col(\"UsageDate\").desc())\n",
    "df_with_rank = df.withColumn(\"rank\", row_number().over(window_spec))\n",
    "\n",
    "df_latest_per_resource = df_with_rank.filter(col(\"rank\") == 1).drop(\"rank\")\n",
    "\n",
    "df_resources = df_latest_per_resource.select(\n",
    "    \"ResourceName\",\n",
    "    \"SubscriptionId\",\n",
    "    \"ResourceGroup\",\n",
    "    \"Provider\",\n",
    "    \"StatusRecourse\",\n",
    "    \"Currency\",\n",
    "    \"TendenciaCusto\"\n",
    ")\n",
    "\n",
    "df_resources = df_resources.withColumn('concat', concat_ws(\"_\", col(\"ResourceName\"), col(\"SubscriptionId\"), col(\"ResourceGroup\")))\n",
    "\n",
    "df_resources = df_resources.join(df_id, on=\"concat\", how=\"left\").drop(\"concat\")\n",
    "\n",
    "df_resources = df_resources.select(\n",
    "    \"Id\",\n",
    "    \"ResourceName\",\n",
    "    \"SubscriptionId\",\n",
    "    \"ResourceGroup\",\n",
    "    \"Provider\",\n",
    "    \"StatusRecourse\",\n",
    "    \"Currency\",\n",
    "    \"TendenciaCusto\"\n",
    ")\n",
    "\n",
    "df_resources.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "262ac6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados inseridos com sucesso na tabela 'resources'.\n"
     ]
    }
   ],
   "source": [
    "jdbc_url = f\"jdbc:postgresql://{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "properties = {\n",
    "    \"user\": DB_USER,\n",
    "    \"password\": DB_PASSWORD,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "df_resources.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"url\", jdbc_url) \\\n",
    "  .option(\"dbtable\", \"resources\") \\\n",
    "  .option(\"user\", DB_USER) \\\n",
    "  .option(\"password\", DB_PASSWORD) \\\n",
    "  .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()\n",
    "\n",
    "print(\"Dados inseridos com sucesso na tabela 'resources'.\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ab0d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+---------------+-------------------+\n",
      "|Id |PreTaxCost|Pct_Change|PrevisaoProxima|UsageDate          |\n",
      "+---+----------+----------+---------------+-------------------+\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 16:00:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 15:55:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 15:50:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 15:45:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 15:40:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 15:35:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 15:30:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 15:25:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 15:20:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 15:15:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 15:10:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 15:05:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 15:00:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 14:55:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 14:50:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 14:45:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 14:40:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 14:35:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 14:30:00|\n",
      "|1  |0.0       |0.0       |0.0            |2025-08-01 14:25:00|\n",
      "+---+----------+----------+---------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(\n",
    "    \"ResourceName\",\n",
    "    \"SubscriptionId\",\n",
    "    \"ResourceGroup\",\n",
    "    \"Provider\",\n",
    "    \"StatusRecourse\",\n",
    "    \"PreTaxCost\",\n",
    "    \"Pct_Change\",\n",
    "    \"Currency\",\n",
    "    \"UsageDate\",\n",
    "    \"TendenciaCusto\",\n",
    "    \"PrevisaoProxima\"\n",
    ")\n",
    "\n",
    "df = df.withColumn('concat', concat_ws(\"_\", col(\"ResourceName\"), col(\"SubscriptionId\"), col(\"ResourceGroup\")))\n",
    "\n",
    "df_prices = df.join(df_id, on=\"concat\", how=\"left\").drop(\"concat\").drop(\"concat\")\n",
    "\n",
    "df_prices = df_prices.select(\n",
    "    \"Id\",\n",
    "    \"PreTaxCost\",\n",
    "    \"Pct_Change\",\n",
    "    \"PrevisaoProxima\",\n",
    "    \"UsageDate\"\n",
    ")\n",
    "\n",
    "df_prices.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f5f12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados inseridos com sucesso na tabela 'costresources'.\n"
     ]
    }
   ],
   "source": [
    "jdbc_url = f\"jdbc:postgresql://{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "properties = {\n",
    "    \"user\": DB_USER,\n",
    "    \"password\": DB_PASSWORD,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "df_prices.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"url\", jdbc_url) \\\n",
    "  .option(\"dbtable\", \"costresources\") \\\n",
    "  .option(\"user\", DB_USER) \\\n",
    "  .option(\"password\", DB_PASSWORD) \\\n",
    "  .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()\n",
    "\n",
    "print(\"Dados inseridos com sucesso na tabela 'costresources'.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b459d5",
   "metadata": {},
   "source": [
    "## Para visualizações do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79091017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bancos de dados disponíveis:\n",
      "postgres\n",
      "airflow\n",
      "template1\n",
      "template0\n",
      "azurecost\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "\n",
    "DB_HOST = \"airflow-postgres\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_USER = os.getenv('POSTGRES_USER')\n",
    "DB_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "\n",
    "# Abre conexão com o banco padrão\n",
    "conn = psycopg2.connect(\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=\"postgres\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Executa a consulta para listar os bancos de dados\n",
    "cur.execute(\"SELECT datname FROM pg_database;\")\n",
    "databases = cur.fetchall()\n",
    "\n",
    "print(\"Bancos de dados disponíveis:\")\n",
    "for db in databases:\n",
    "    print(db[0])\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25211f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelas no banco 'airflow':\n",
      "log\n",
      "dag_priority_parsing_request\n",
      "job\n",
      "slot_pool\n",
      "callback_request\n",
      "dag_code\n",
      "dag_pickle\n",
      "ab_user\n",
      "ab_register_user\n",
      "connection\n",
      "sla_miss\n",
      "variable\n",
      "import_error\n",
      "serialized_dag\n",
      "dataset_alias\n",
      "dataset_alias_dataset\n",
      "dataset\n",
      "dataset_alias_dataset_event\n",
      "dataset_event\n",
      "dag_schedule_dataset_alias_reference\n",
      "dag\n",
      "dag_schedule_dataset_reference\n",
      "task_outlet_dataset_reference\n",
      "dataset_dag_run_queue\n",
      "log_template\n",
      "dag_run\n",
      "dag_tag\n",
      "dag_owner_attributes\n",
      "ab_permission\n",
      "ab_permission_view\n",
      "ab_view_menu\n",
      "ab_user_role\n",
      "ab_role\n",
      "dag_warning\n",
      "dagrun_dataset_event\n",
      "trigger\n",
      "task_instance\n",
      "dag_run_note\n",
      "ab_permission_view_role\n",
      "rendered_task_instance_fields\n",
      "task_fail\n",
      "task_map\n",
      "task_reschedule\n",
      "xcom\n",
      "task_instance_note\n",
      "task_instance_history\n",
      "session\n",
      "alembic_version\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "\n",
    "DB_HOST = \"airflow-postgres\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_USER = os.getenv('POSTGRES_USER')\n",
    "DB_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "DB_NAME = \"airflow\"\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=DB_NAME\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Query para listar tabelas do schema 'public'\n",
    "cur.execute(\"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'public'\n",
    "    AND table_type = 'BASE TABLE';\n",
    "\"\"\")\n",
    "\n",
    "tables = cur.fetchall()\n",
    "\n",
    "print(f\"Tabelas no banco '{DB_NAME}':\")\n",
    "for table in tables:\n",
    "    print(table[0])\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c33f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas da tabela 'dag':\n",
      "Nome: dag_id, Tipo: character varying, Pode ser NULL: NO, Default: None\n",
      "Nome: root_dag_id, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: is_paused, Tipo: boolean, Pode ser NULL: YES, Default: None\n",
      "Nome: is_subdag, Tipo: boolean, Pode ser NULL: YES, Default: None\n",
      "Nome: is_active, Tipo: boolean, Pode ser NULL: YES, Default: None\n",
      "Nome: last_parsed_time, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n",
      "Nome: last_pickled, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n",
      "Nome: last_expired, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n",
      "Nome: scheduler_lock, Tipo: boolean, Pode ser NULL: YES, Default: None\n",
      "Nome: pickle_id, Tipo: integer, Pode ser NULL: YES, Default: None\n",
      "Nome: fileloc, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: processor_subdir, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: owners, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: dag_display_name, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: description, Tipo: text, Pode ser NULL: YES, Default: None\n",
      "Nome: default_view, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: schedule_interval, Tipo: text, Pode ser NULL: YES, Default: None\n",
      "Nome: timetable_description, Tipo: character varying, Pode ser NULL: YES, Default: None\n",
      "Nome: dataset_expression, Tipo: json, Pode ser NULL: YES, Default: None\n",
      "Nome: max_active_tasks, Tipo: integer, Pode ser NULL: NO, Default: None\n",
      "Nome: max_active_runs, Tipo: integer, Pode ser NULL: YES, Default: None\n",
      "Nome: max_consecutive_failed_dag_runs, Tipo: integer, Pode ser NULL: NO, Default: None\n",
      "Nome: has_task_concurrency_limits, Tipo: boolean, Pode ser NULL: NO, Default: None\n",
      "Nome: has_import_errors, Tipo: boolean, Pode ser NULL: YES, Default: false\n",
      "Nome: next_dagrun, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n",
      "Nome: next_dagrun_data_interval_start, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n",
      "Nome: next_dagrun_data_interval_end, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n",
      "Nome: next_dagrun_create_after, Tipo: timestamp with time zone, Pode ser NULL: YES, Default: None\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "\n",
    "DB_HOST = \"airflow-postgres\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_USER = os.getenv('POSTGRES_USER')\n",
    "DB_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "DB_NAME = \"airflow\" \n",
    "\n",
    "table_name = 'dag'\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=DB_NAME\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT column_name, data_type, is_nullable, column_default\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = 'public'\n",
    "    AND table_name = %s\n",
    "    ORDER BY ordinal_position;\n",
    "\"\"\", (table_name,))\n",
    "\n",
    "columns = cur.fetchall()\n",
    "\n",
    "print(f\"Colunas da tabela '{table_name}':\")\n",
    "for col in columns:\n",
    "    print(f\"Nome: {col[0]}, Tipo: {col[1]}, Pode ser NULL: {col[2]}, Default: {col[3]}\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d6bab6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela 'costresources' excluída com sucesso.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    drop_table_query = \"DROP TABLE IF EXISTS costresources;\"\n",
    "    cur.execute(drop_table_query)\n",
    "    print(f\"Tabela 'costresources' excluída com sucesso.\")\n",
    "\n",
    "    cur.close()\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Erro ao excluir a tabela: {e}\")\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec007fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banco de dados 'azurecost' excluído com sucesso.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=\"postgres\",  # banco diferente do que será dropado\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Fecha conexões ativas no banco azurecost\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT pg_terminate_backend(pid) \n",
    "        FROM pg_stat_activity \n",
    "        WHERE datname = %s;\n",
    "    \"\"\", (DB_NAME,))\n",
    "\n",
    "    # Exclui o banco azurecost\n",
    "    cur.execute(f\"DROP DATABASE IF EXISTS {DB_NAME};\")\n",
    "    print(f\"Banco de dados '{DB_NAME}' excluído com sucesso.\")\n",
    "\n",
    "    cur.close()\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Erro ao excluir o banco de dados: {e}\")\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
